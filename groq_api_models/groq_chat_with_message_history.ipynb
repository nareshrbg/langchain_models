{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0df0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c0985d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001FD6C551A00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001FD6C642750>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae2c8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Naresh,\\n\\nIt's great to meet you! \\n\\nLearning about Generative AI is exciting. It's a rapidly evolving field with incredible potential. \\n\\nWhat specifically are you interested in learning about GenAI? \\n\\nPerhaps I can help you with:\\n\\n* **Understanding the basics:** What is GenAI, how does it work, and what are some examples?\\n* **Exploring different types of GenAI models:** Text generation, image generation, code generation, etc.\\n* **Learning about specific applications:** Chatbots, creative writing, drug discovery, etc.\\n* **Getting started with GenAI tools:** There are many open-source and commercial tools available.\\n\\nJust let me know what you'd like to explore, and I'll do my best to assist you.  Good luck with your learning journey!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 176, 'prompt_tokens': 23, 'total_tokens': 199, 'completion_time': 0.32, 'prompt_time': 0.005006738, 'queue_time': 0.29292862, 'total_time': 0.325006738}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--27c7487f-44a5-40a0-a0e1-d4a1c03b0974-0', usage_metadata={'input_tokens': 23, 'output_tokens': 176, 'total_tokens': 199})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"Hi , My name is Naresh and I am learning GenAI now\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e822fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and don't know your name or what you do. \\n\\nYou introduced yourself as Naresh at the beginning of our conversation.  \\n\\nIs there anything else I can help you with?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 219, 'total_tokens': 272, 'completion_time': 0.096363636, 'prompt_time': 0.010192032, 'queue_time': 0.24318567900000002, 'total_time': 0.106555668}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--e0a7fbe3-18ef-4239-92c4-eb7a11a53c4c-0', usage_metadata={'input_tokens': 219, 'output_tokens': 53, 'total_tokens': 272})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , My name is Naresh and I am learning GenAI now\"),\n",
    "        AIMessage(content=\"Hi Naresh,\\n\\nIt's great to meet you! \\n\\nLearning about Generative AI is exciting. It's a rapidly evolving field with incredible potential. \\n\\nWhat specifically are you interested in learning about GenAI? \\n\\nPerhaps I can help you with:\\n\\n* **Understanding the basics:** What is GenAI, how does it work, and what are some examples?\\n* **Exploring different types of GenAI models:** Text generation, image generation, code generation, etc.\\n* **Learning about specific applications:** Chatbots, creative writing, drug discovery, etc.\\n* **Getting started with GenAI tools:** There are many open-source and commercial tools available.\\n\\nJust let me know what you'd like to explore, and I'll do my best to assist you.  Good luck with your learning journey!\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Here, models are stateless and it does not have previous context even if data is sent as history in messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "928cd74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "# Get seesion id which is stored in inmemory message history.\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a49a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Naresh,\\n\\nIt's great to meet you!  I'm glad you're learning about Generative AI. It's a fascinating field with a lot of potential. \\n\\nWhat specifically are you interested in learning about GenAI?  \\n\\nDo you have any questions I can help you with, or are you just looking for information on where to start?  \\n\\nI can offer resources, explain concepts, or even generate some examples of GenAI in action. Just let me know!\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n",
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My name is Naresh and I am learning GenAI now\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1beb5c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi , My name is Naresh and I am learning GenAI now', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Naresh, it's great to meet you! \\n\\nWelcome to the world of Generative AI. It's a fascinating field with a lot of potential. What specifically are you interested in learning about GenAI? \\n\\nPerhaps I can help you with:\\n\\n* **Understanding the basics:** What is GenAI, its capabilities, and how it works?\\n* **Exploring different types of GenAI models:** Text generation, image generation, code generation, etc.\\n* **Learning about specific applications:** Chatbots, creative writing, drug discovery, etc.\\n* **Getting hands-on with GenAI tools:** There are many open-source and commercial tools available.\\n\\nJust let me know what you'd like to explore, and I'll do my best to guide you.  Good luck with your learning journey!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 174, 'prompt_tokens': 23, 'total_tokens': 197, 'completion_time': 0.316363636, 'prompt_time': 0.00216833, 'queue_time': 0.24618535, 'total_time': 0.318531966}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--e45c0acb-dd96-4af9-892f-1127ff878467-0', usage_metadata={'input_tokens': 23, 'output_tokens': 174, 'total_tokens': 197})])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f86aa0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.chat_history.InMemoryChatMessageHistory"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(store['chat1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d00026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chat prompt template\n",
    "prompt=ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Amnswer all the question to the nest of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "parser=StrOutputParser()\n",
    "chain=prompt|model|parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc3f6867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative Artificial Intelligence: AI that creates new content.  \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'messages': [HumanMessage(content=\"Define GenAI in 10 words\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "933854e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Naresh, it's nice to meet you!\\n\\nI'm happy to help with any questions you have. Just ask away, and I'll do my best to provide you with useful and informative answers.  ðŸ˜Š \\n\\nWhat can I do for you today? \\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run with runnable message history to run along with previous session history messages\n",
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)\n",
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Naresh\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9340ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding params to system or human messages\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Explain about {topic} with in 5 words.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "# chain.invoke({'messages':[HumanMessage(content='Elaborate the topic adding 2 extra words')], 'language':'English','topic':'GenAI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2172e941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant. Answer all questions to the best of your ability in English.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain about GenAI with in 5 words.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Elaborate the topic adding 2 extra words', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({'messages':[HumanMessage(content='Elaborate the topic adding 2 extra words')], 'language':'English','topic':'GenAI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff17b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'à¤®à¤¶à¥€à¤¨à¥‹à¤‚ à¤•à¥‹ à¤¸à¥€à¤–à¤¨à¥‡ à¤®à¥‡à¤‚ à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ à¤•à¤°à¤¨à¤¾ \\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's now wrap this more complicated chain in a Message History class. This time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history.\"\"\"\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat5\"}}\n",
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Elaborate the topic adding 2 extra words\")],\"language\":\"Hindi\", 'topic':'Machine learning'},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a94ad8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Elaborate the topic adding 2 extra words', additional_kwargs={}, response_metadata={}), AIMessage(content='à¤œà¤¨à¤°à¥‡à¤Ÿà¤¿à¤µ à¤†à¤°à¥à¤Ÿà¤¿à¤«à¤¿à¤¶à¤¿à¤¯à¤² à¤‡à¤‚à¤Ÿà¥‡à¤²à¤¿à¤œà¥‡à¤‚à¤¸  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 56, 'total_tokens': 76, 'completion_time': 0.036363636, 'prompt_time': 0.003478754, 'queue_time': 0.243668316, 'total_time': 0.03984239}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--14c2334d-217a-463b-b460-3c96fe26f054-0', usage_metadata={'input_tokens': 56, 'output_tokens': 20, 'total_tokens': 76}), HumanMessage(content='Elaborate the topic adding 2 extra words', additional_kwargs={}, response_metadata={}), AIMessage(content='à¤®à¤¶à¥€à¤¨à¥‹à¤‚ à¤•à¥‹ à¤¸à¥€à¤–à¤¨à¥‡ à¤®à¥‡à¤‚ à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ à¤•à¤°à¤¨à¤¾ \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 93, 'total_tokens': 110, 'completion_time': 0.030909091, 'prompt_time': 0.005223109, 'queue_time': 0.24539663, 'total_time': 0.0361322}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--c394c38d-8fab-4002-a353-896700285986-0', usage_metadata={'input_tokens': 93, 'output_tokens': 17, 'total_tokens': 110})])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['chat5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e95992",
   "metadata": {},
   "source": [
    "### Trimming the Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e7a4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Development\\langchain\\langchain_models\\lang_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "e:\\Development\\langchain\\langchain_models\\lang_venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c57dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain2 = prompt2 | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18c205a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I have no memory of past conversations. To help me answer your question, please provide the math problem you'd like me to solve. ðŸ˜Š  \\n\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter messages through chain\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain2=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt2\n",
    "    | model\n",
    ")\n",
    "response=chain2.invoke(\n",
    "    {\n",
    "    \"messages\":[HumanMessage(content=\"what math problem did i ask\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "056d755e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked \"what\\'s 2 + 2\". ðŸ˜Š  \\n\\n\\n\\nDo you want to try another one?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 86, 'total_tokens': 112, 'completion_time': 0.047272727, 'prompt_time': 0.005314469, 'queue_time': 0.24331381000000002, 'total_time': 0.052587196}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--164273a5-9df2-4c9f-a360-2ead0febbced-0', usage_metadata={'input_tokens': 86, 'output_tokens': 26, 'total_tokens': 112})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt2\n",
    "    | model\n",
    ")\n",
    "chain2.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6d0e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send filtered messages through RunnableWithMessageHistory\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain2,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat7\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f64b8e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"what is 2 + 2\" ðŸ˜Š  \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\":messages + [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\"\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked \"whats 2 + 2\"  ðŸ¦  \n",
      "\n",
      "\n",
      "\n",
      "Let me know if you'd like to try another one! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.messages import trim_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from operator import itemgetter\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize model\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\", groq_api_key=groq_api_key)\n",
    "\n",
    "# Define trimmer\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "# Message history\n",
    "history = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "# Define prompt\n",
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Chain with correct trimming and history injection\n",
    "chain2 = (\n",
    "    RunnablePassthrough.assign(\n",
    "        messages=RunnableLambda(itemgetter(\"messages\")) | trimmer\n",
    "    )\n",
    "    | prompt2\n",
    "    | model\n",
    ")\n",
    "\n",
    "# Invoke with current input\n",
    "response = chain2.invoke({\n",
    "    \"messages\": history,\n",
    "    \"input\": \"what math problem did I ask?\"\n",
    "})\n",
    "\n",
    "# Print the output\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21670779",
   "metadata": {},
   "source": [
    "## Second & correct type of chat history runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8c636f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data-driven decision making by machines. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get seesion id which is stored in inmemory message history.\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory() # ChatMessageHistory save Humanmessage and AImessages\n",
    "    return store[session_id]\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond only in {language}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"human\",\"{input}\")\n",
    "])\n",
    "parser=StrOutputParser()\n",
    "base_chain = prompt | model | parser\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    base_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\", # Current input\n",
    "    history_messages_key=\"messages\" # This gets and saves old and current input dfrom user \n",
    ")\n",
    "config = {\"configurable\": {\"session_id\": \"chat11\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"input\": \"Explain about ML in 5 words\",\n",
    "        \"language\":\"English\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
